{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/worldbank/dec-python-course/blob/main/1-foundations/3-numpy-and-pandas/foundations-s3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1N3qhyA0T3w"
   },
   "source": [
    "# Sesion 3 - Paquetes y limpieza de datos con Pandas\n",
    "\n",
    "En esta sesión introduciremos los paquetes de Python: qué son y cómo usarlos. Luego nos enfocaremos en dos paquetes que son muy utilizados en ciencia de datos: pandas y matplotlib. El primero se usa para analisis y limpieza de datos y el segundo para visualizacion.\n",
    "\n",
    "# 1. Bibliotecas de Python\n",
    "\n",
    "Dentro del mundo de Python, un paquete es una colección de módulos, y una biblioteca es una colección de paquetes. En la práctica, los términos \"biblioteca de Python\" y \"paquete de Python\" se usan de manera similar para referirse a un fragmento reutilizable de código. El uso de bibliotecas nos permite utilizar codigo que ha sido desarrollado y compartido por otros programadores de modo que nosotros no tengamos que escribir todo desde cero.\n",
    "\n",
    "## 1.1. Algunos ejemplos de bibliotecas de Python\n",
    "\n",
    "- [pandas](https://pandas.pydata.org/) es una biblioteca de Python para el procesamiento rápido y eficiente de tablas de datos, series de tiempo, datos en matrices, etc.\n",
    "- [Matplotlib](https://matplotlib.org/) es una biblioteca completa para crear visualizaciones de datos en Python.\n",
    "- [NumPy](https://numpy.org/) significa \"Numerical Python\". Es la biblioteca fundamental de Python para la computación científica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-1OvfSZ2e5m"
   },
   "source": [
    "## 1.2. Como usar paquetes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNtSS8HZeIV5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6CkPZNx20Lq"
   },
   "source": [
    "`import` followed by the library name loads the library into the environment. `as` is optional; it is usually used to alias the library name to a shorthand or for disambiguation. The above are some conventional aliases for these libraries. If you `import numpy` without aliasing, just be sure to use `numpy` instead of `np` when calling the library's functions later.\n",
    "\n",
    "`import` the library like you would import a built-in python module works for common libraries on most cloud-based python notebook environments (e.g. Google Colab and Databricks) because they already pre-installed many common libraries like Pandas and NumPy.\n",
    "\n",
    "`import` seguido del nombre del paquete carga el paquete para que podamos utilizarlo. `as` es opcional; generalmente se usa para asignar un \"alias\" al nombre del paquete como una forma abreviada o para evitar ambigüedades. Los alias mostrados arriba son convencionales para estas bibliotecas. Si haces `import numpy` sin alias, solo asegúrate de usar `numpy` en lugar de `np` al llamar las funciones del paquete más adelante.\n",
    "\n",
    "Usar `import` para importar un paquete, al igual que se hace con los módulos incorporados de Python, funciona para paquetes usados comunmente en la mayoría de los entornos de notebooks en la nube (por ejemplo, para el que ustamos usando ahora, Jupyter Lite). Estos entornos usualmente ya vienen con muchos paquetes pre-instalados, como Pandas y Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrdT4xNYdqZ1"
   },
   "source": [
    "## 1.3. ¿Qué paquetes vienen preinstalados?\n",
    "\n",
    "[pip](https://pip.pypa.io/) es por defecto la herramienta para instalar paquetes en Python. Puedes usarlo para ver los paquetes actualmente instalados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CBYYko-23YKA"
   },
   "outputs": [],
   "source": [
    "# Nota: El simbolo ! en un entorno de notebook ejecuta un comando de \"bash\"\n",
    "# Bash es otro lenguaje de programacion. Es necesario usar el simbolo !\n",
    "# porque esto indica a nuestro que este es un comando Bash y que no es Python\n",
    "\n",
    "# `| head` acorta la salida para mostrar solo las primeras 10 líneas\n",
    "\n",
    "!pip freeze | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eZ2_CmN4Mzq"
   },
   "source": [
    "## 1.4. ¿Puedo instalar una nueva biblioteca?\n",
    "\n",
    "Nuevamente, usamos el gestor de paquetes `pip` para instalar un nuevo paquete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jiOOOA9w4UeG"
   },
   "outputs": [],
   "source": [
    "# Instala el paquete `wbgapi` para acceder programáticamente a la base de datos por paises del Banco Mundial\n",
    "!pip install wbgapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzycubXAOqiK"
   },
   "source": [
    "## 1.5 ¿Donde esta la documentacion e informacion sobre un paquete?\n",
    "\n",
    "Puedes preguntar a Google o a ChatGPT, o consultar directamente la documentación oficial de la biblioteca:\n",
    "\n",
    "- Documentación de Pandas (en espanol): https://pandas-pydata-org.translate.goog/docs/?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es&_x_tr_pto=tc\n",
    "\n",
    "Dentro de un notebook, siempre puedes usar `help()` para ver la documentación (en ingles) de cualquier función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHsjXa3gQSbX"
   },
   "outputs": [],
   "source": [
    "help(pd.isna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQbrnlL81xm7"
   },
   "source": [
    "# 2. Pandas\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*6d5dw6dPhy4vBp2vRW6uzw.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apd7GljeDz59"
   },
   "source": [
    "Los datos con los que trabajamos a menudo tienen **forma de tabla** o tabular –como hojas de cálculo de Excel– y contienen tipos de datos mixtos: algunos numéricos, otros categóricos y otros textuales. Antes de poder realizar operaciones matemáticas complejas y análisis significativos con datos, como visualizacion de datos o analisis de textos, normalmente necesitamos primero explorar y pre-procesar los datos. Este proceso implica operaciones como limpieza, reestructuración, filtrado, etc. Para esto usamos Pandas.\n",
    "\n",
    "Dato curioso: ¿De donde viene el nombre Pandas? Aparentemente, el nombre proviene del término \"panel data\" (datos de panel).\n",
    "\n",
    "Pandas y muchas otros paquetes en Python tienen sus propios tipos de variables en lugar de operar directamente con los tipos basicos que vimos en las dos primeras sesions. `Series` y `DataFrame` son los tipos básicos de Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSpeS492gLEW"
   },
   "source": [
    "## 2.1. Series\n",
    "\n",
    "`Series` es un conjunto de datos ordenado con un \"indice\" para cada elemento. Puede contener **cualquier tipo de dato**. Los por defecto muestran la posicion de cada elemento, comenzando en cero.\n",
    "\n",
    "La palabra es singular por ser en ingles, pero vamos a referirnos a este tipo tambien diciendola en singular en espanol: `Serie`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec5MCn0bg-EP"
   },
   "source": [
    "### Como crear una serie?\n",
    "\n",
    "Usamos el comando `Series()` de Pandas. Puedes partir de una lista y transformarla en una serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbbahkW1h2Fg"
   },
   "outputs": [],
   "source": [
    "lista = [10, 20, 30]\n",
    "serie = pd.Series(lista)\n",
    "serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- la primera columna muestra el indice de cada valor. Por defecto, estas se asignan como la posicion de los elementos comenzando en cero\n",
    "- la segunda columna muestra los valores de la serie\n",
    "\n",
    "Tambien podemos asignar indices explicitamente mediante el argumento `index` en el comando `Series()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZIWcxaKfhanx"
   },
   "outputs": [],
   "source": [
    "# especificando los indices usando \"index\"\n",
    "serie_con_indices = pd.Series([10, 20, 30], index=[\"valor 1\", \"valor 2\", \"valor 3\"])\n",
    "serie_con_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los nombres de los indices permiten extraer elementos de una serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15h1ZumAip1f"
   },
   "outputs": [],
   "source": [
    "serie_con_indices[\"valor 2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peq4eUTujAI-"
   },
   "outputs": [],
   "source": [
    "serie[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8oV6eavh0Wx"
   },
   "source": [
    "### Como transformar una serie en una lista?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEK4BJCTh0W7"
   },
   "outputs": [],
   "source": [
    "serie_con_indices.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXyQLgt9QN_k"
   },
   "source": [
    "### ¿Puedo aplicar la misma transformación a cada elemento de una Serie?\n",
    "\n",
    "Si. La forma depende de la transformacion que estemos aplicando:\n",
    "\n",
    "**Operaciones matematicas en series con numeros**\n",
    "\n",
    "Podemos operar directamente la serie con simbolos mateticos. La operacion se aplicara a cada elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie + 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aplicando una funcion a una serie**\n",
    "\n",
    "Para esto utilizamos el metodo `.map()`, que se puede usar en series. Este metodo aplica una funcion a **cada elemento de la serie de forma individual**.\n",
    "\n",
    "Veamos el siguiente ejemplo, que aplica una funcion a los valores de una serie que contiene strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo una funcion que invierte los caracteres de una string:\n",
    "def al_reves(texto):\n",
    "    \n",
    "    texto_invertido = texto[::-1]\n",
    "    \n",
    "    return texto_invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo una nueva serie:\n",
    "paises = ['Republica Dominicana', 'El Salvador', 'Peru']\n",
    "serie_paises = pd.Series(paises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando la funcion a la serie:\n",
    "serie_paises.map(al_reves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es mas o menos similar a haber aplicado la funcion a cada elemento en un bucle `for`, que revisamos ayer. Sin embargo, hay una diferencia fundamental en terminos del tiempo requerido: **esta es una operacion vectorizada**. Esto significa que Python aplica la operacion a todos los elementos al mismo tiempo, mientras que en un bucle `for` las transformaciones de cada elemento solo comienzan luego de que la transformacion al elemento anterior ya culmino.\n",
    "\n",
    "Dado que estos son solo tres elementos, nuestra percepcion de tiempo no nos permite distinguir la diferencia en el tiempo que toma una operacion vectorizada y un bucle `for`. Pero cuando trabajamos con miles o millones de observaciones, esto hace una gran diferencia.\n",
    "\n",
    "**Conclusion:** siempre procura aplicar operaciones vectorizadas al trabajar con Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yj-JuBEuhhvG"
   },
   "source": [
    "## 2.2. DataFrame\n",
    "\n",
    "Un `DataFrame` es una tabla de datos con indices para las filas y nombres para las columnas. Las columnas pueden tener distintos tipos de datos. Puedes entender un `DataFrame` como similar a una hoja de cálculo en Excel o una tabla en SQL. Generalmente, es el tipo de variable más utilizado de pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCQIFZbgLKTl"
   },
   "source": [
    "### 3.2.1. Creación de DataFrames\n",
    "\n",
    "Hay muchas formas de crear un `DataFrame`. Veamos algunos ejemplos utilizando los tipos de datos con los que ya estamos familiarizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kec7XEzdiTC5"
   },
   "source": [
    "#### Utilizando una `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcAkiwxGib61"
   },
   "outputs": [],
   "source": [
    "datos = {\"paises\": serie_paises, \"valores\": serie}\n",
    "df_usando_series = pd.DataFrame(datos)\n",
    "df_usando_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOQ_nHiSkukP"
   },
   "outputs": [],
   "source": [
    "df_usando_series.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFENQGSSlm8h"
   },
   "outputs": [],
   "source": [
    "df_usando_series.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKZJgFi9m1kL"
   },
   "source": [
    "#### Usando listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8E02RfDEm6h3"
   },
   "outputs": [],
   "source": [
    "datos = {\"ID\": [1, 2], \"mascota\": [\"perro\", \"gato\"], \"necesita paseo\": [True, False]}\n",
    "mascotas = pd.DataFrame(datos)\n",
    "mascotas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urMFL5Q3pDsW"
   },
   "source": [
    "#### Desde un archivo CSV de internet\n",
    "\n",
    "Usamos el comando `read_csv()` de pandas para leer un archivo CSV. El input puede ser una direccion en internet (URL) o un archivo CSV en nuestra computadora (por ejemplo: `C:/Documentos/tabla.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ZPpStkhpbZn"
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/worldbank/dec-python-course/main/1-foundations/3-numpy-and-pandas/data/Singapore_Annual_New_Car_Registrations_by_make_type.csv'\n",
    "singapore_cars = pd.read_csv(url)\n",
    "singapore_cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desde un archivo de Excel\n",
    "\n",
    "Usamos el comando `read_excel()`. Si un archivo de Excel tiene muchas tablas, podemos especificar que tabla queremos leer con el argumento `sheet_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_excel = 'datos/BOLETIN ESTADISTICO 2024.xlsx'\n",
    "df = pd.read_excel(archivo_excel, sheet_name='Recaudación por región')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este DataFrame sera el que utilizaremos para los ejemplos y ejercicios del resto de la sesion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPPh4jhhw2uR"
   },
   "source": [
    "### 2.2.2. Explorando los datos\n",
    "\n",
    "Ahora hagamos una exploracion básica para entender nuestro DataFrame.\n",
    "\n",
    "#### ¿Cuántas filas y columnas hay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len() aplicado a un DataFrame da el numero de filas\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_skn1V2xH2z"
   },
   "outputs": [],
   "source": [
    "# .shape nos da las filas y columnas\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6NNO7EXXzptW"
   },
   "outputs": [],
   "source": [
    "n_filas, n_columnas = df.shape\n",
    "print(f'Tenemos {n_filas} filas y {n_columnas} columnas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4P7htLGvxs7N"
   },
   "source": [
    "#### Cuales son los nobres de las columnas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzHsABg4xKwB"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXxyBZVoyE16"
   },
   "source": [
    "#### ¿Cómo se ven los datos?\n",
    "\n",
    "Desde las primeras observaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsU42CC8yKTc"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52ELu1E5x0GV"
   },
   "source": [
    "Desde las ultimas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QaUtw33ySXz"
   },
   "outputs": [],
   "source": [
    "# Opcionalmente, podemos especificar cuantas de las ultimas filas queremos ver\n",
    "df.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dII_PI_y9uU"
   },
   "source": [
    "#### ¿Qué tipo de datos contiene actualmente cada columna y cuántos valores faltantes hay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vSbYN4zyXvK"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observamos, este DataFrame necesita procesamiento para ser util en visualizacion de datos u otras operaciones. Los datos originales en Excel se ven como en la siguiente captura de pantalla:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/recaudacion-por-region.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los siguientes ejercicios, vamos a transformar los para que tengan una forma en la que podamos realizar visualizaciones usando `matplotlib`. Especificamente, esto es lo que haremos:\n",
    "\n",
    "1. Crear un dataframe a nivel de provincia con la recaudacion de 2015 a 2024\n",
    "1. Crear otro dataframe a nivel de region con la recaudacion por region de 2015 a 2024\n",
    "1. Crear otro dataframe a nivel de provincia con la participacion por provincia en la recaudacion total de la region, solo para la region norte, en 2024.\n",
    "\n",
    "Como primer paso, empezaremos por eliminar las filas que no contienen informacion.\n",
    "\n",
    "### 2.2.3 Seleccionando filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a visualizar el DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La informacion que queremos preservar esta de las filas 9 a la 43. Dejaremos solo esas filas en el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nota que como queremos hasta la fila 43, el ultimo indice debe ser uno mas (44)\n",
    "# todos los rangos en Python son excluyentes del ultimo numero\n",
    "df = df[9:44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per vemos que el indice ahora va de 9 a 43! para que vuelva a empezar en cero, usamos `reset_index(drop=True)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora el indice es correcto.\n",
    "\n",
    "### 2.2.4 Renombrando columnas\n",
    "\n",
    "A continuacion, asignaremos los nombres correctos a las columnas. Empezaremos creando una lista de strings con los nombres que queremos asignar. Para esto usamos un tipo de operacion sumamente util en Python: **comprension de listas** (*list comprehension*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f'recaudacion {num}' for num in range(2015, 2025)]\n",
    "# nota que el ultimo elemento del rango es 2025, eso indica que el ranga va hasta 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Provincia'] + cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto, asignamos los nombres a las columnas con `df.columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = cols\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, cambiamos todos los nombres de las columnas en una sola operacion. Para cambiar una sola, podemos usar el metodo `.rename()`. Lo utilizaremos ahora para cambiar la primera columna de `Provincia` a `provincia` (con `p` minuscula). En analisis de datos, usualmente es mas conveniente mantener nombres de columnas siempre en minusculas y sin acentos.\n",
    "\n",
    "Nota que el argumento donde definimos los nuevos nombres de las columnas **es un diccionario** que relaciona los nombres antiguos con los nuevos. Este diccionario se asigna al argumento llamado `columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos_nombres = {'Provincia': 'provincia'}\n",
    "df = df.rename(columns=nuevos_nombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Reemplazando valores de una columna\n",
    "\n",
    "Habras notado que Pandas no leyo los valores de Excel en millones de pesos dominicanos, sino en pesos directamente. Para corregir esto, vamos a transformar los valores a millones de pesos. Empezaremos con una sola columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recaudacion 2015'] = df['recaudacion 2015'] / 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso de corchetes selecciona una columna de un dataframe por su nombre, que va como una string dentro de los corchetes.\n",
    "\n",
    "Podemos seguir aplicando esta operacion columna por columna de 2016 a 2024, pero tardariamos mucho. Otra opcion mas conveniente es usar esta forma de seleccionar columnas con **multiples columnas**.\n",
    "\n",
    "### 2.2.6 Reemplazando valores en varias columnas a la vez\n",
    "\n",
    "Para esto volveremos a nuestra lista `cols` que definimos antes. Solo que debemos modificarla para que incluya las columnas que queremos cambiar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = cols[2:]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols] = df[cols] / 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota que `cols` es una lista! de modo que `df[cols]` es igual a `df[['recaudacion 2016', 'recaudacion 2017', .........]]`.\n",
    "\n",
    "Ahora comprobaremos si la operacion funciono:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos cada vez mas cerca a lograr tener los datos en la forma que necesitamos, pero aun nos faltan algunas operaciones. Lo siguiente sera separa `df` en dos dataframes:\n",
    "- uno a nivel de provincia\n",
    "- uno a nivel de region\n",
    "\n",
    "### 2.2.7 Seleccionando (filtrando) filas\n",
    "\n",
    "Empezaremos creando el dataset de las regiones. Para eso primero crearemos una lista con los nombres de las regiones y luego la usaremos para seleccionar las filas con los nombres de regiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regiones = ['Norte', 'Sureste', 'Suroeste']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regiones = df[df['provincia'].isin(regiones)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos puntos a considerar:\n",
    "- El metodo `.isin()` se aplica en una columna de un dataframe y evalua si los valores estan incluidos en una lista dada\n",
    "- El resultado de `.isin()` es una `Series` con valores booleanos, con `True` si el valor estuvo en la lista\n",
    "- Esto significa que el input del primer par de corchetes es una serie de **valores booleanos**. Pandas usa este tipo de valores para determinar que filas son filtradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['provincia'].isin(regiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos que `df_regiones` tiene indices en desorden, nuevamente utilizaremos el metodo `reset_index(drop=True)` para establecer el indice correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regiones = df_regiones.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, cambiaremos el nombre de la columna `provincia` por `region` en df_regiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regiones = df_regiones.rename(columns={'provincia': 'region'})\n",
    "df_regiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solo nos falta filtrar las observaciones de provincias de `df`. Para esto haremos la operacion de seleccion de filas inversa usando el operador logico `~`, que significa \"opuesto\". Esto transforma valores booleanos `True` a `False` y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nota el uso de ~ y que usamos .reset_index() directamente para corregir la numeracion del indice\n",
    "df_provincias = df[~df['provincia'].isin(regiones)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provincias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto ya tenemos 2 de los 3 dataframes que queriamos. Nos falta:\n",
    "- Crear otro dataframe a nivel de provincia con la participacion por provincia en la recaudacion total de la region, solo para la region norte, en 2024.\n",
    "\n",
    "Este dataframe requiere de mas operaciones. En concreto:\n",
    "1. Filtrar solo las provincias de la region norte.\n",
    "1. Filtrar solo las columnas con el nombre de provincia y la recaudacion de 2024\n",
    "1. Del dataframe de regiones, traer el valor de la recaudacion de la region en 2024\n",
    "1. Dividir la recaudacion de cada provincia con la recaudacion de la region en 2024 para obtener la participacion por regiones\n",
    "\n",
    "Algunas de estas operaciones ya las hemos realizado, otras son nuevas. Empezaremos por senalar en `df_provincias` cuales son las provincias de la region norte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provincias_norte = [\n",
    "'Dajabón', \n",
    "'Duarte', \n",
    "'Espaillat', \n",
    "'Hermanas Mirabal', \n",
    "'La Vega', \n",
    "'María Trinidad Sánchez', \n",
    "'Monseñor Nouel', \n",
    "'Montecristi', \n",
    "'Puerto Plata', \n",
    "'Samaná', \n",
    "'Sánchez Ramírez', \n",
    "'Santiago de Los Caballeros', \n",
    "'Santiago Rodríguez', \n",
    "'Valverde Mao'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.8 Creando valores basados en condiciones\n",
    "\n",
    "A continuacion, anadiremos en `df_provincias` una nueva columna llamada `region` que tendra el valor \"Norte\" para todas las provincias del norte. para esto, utilizaremos el seleccionador de dataframes de Pandas `.loc[]`, que permite operaciones de seleccion mas complejas y cambios de valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando una columna con una string vacia\n",
    "df_provincias['region'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provincias.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usaremos el seleccionador `.loc[]`. Nota que esta es su sintaxis para reemplazar valores basados en una condicion:\n",
    "\n",
    "`df.loc[condicion-basada-en-filas, columna-a-cambiar] = nuevo-valor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provincias.loc[df_provincias['provincia'].isin(provincias_norte), 'region'] = 'Norte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_provincias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.9 Seleccionando columnas\n",
    "\n",
    "Ahora procederemos a quedarnos con las columnas `provincia`, `recaudacion 2024` y `region`, para las regiones del norte. Empezaremos seleccionando solo las columnas relevantes y guardaremos el resultado en un dataframe llamado `df_norte`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_que_quedan = ['provincia', 'recaudacion 2024', 'region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norte = df_provincias[columnas_que_quedan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solo queda filtrar las observaciones en el norte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norte = df_norte[df_norte['region'] == 'Norte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya estamos casi listos para unir estos datos con `df_regiones` para traer la recaudacion total del norte en 2024 y calcular la participacion por provincia.\n",
    "\n",
    "### 2.2.10 Uniendo dataframes\n",
    "\n",
    "Empezaremos por filtrar las filas y columnas relevantes en `df_regiones` para dejar solo el norte y 2024:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regiones_norte = df_regiones[df_regiones['region'] == 'Norte'][['region', 'recaudacion 2024']]\n",
    "df_regiones_norte = df_regiones_norte.rename(columns={'recaudacion 2024': 'total region 2024'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_regiones_norte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizaremos la union entre `df_norte` y `df_regiones_norte`, usando el metodo `.merge()`. Este metodo toma los siguientes argumentos:\n",
    "\n",
    "- el metodo se aplica en el **primer dataframe** y el primer argumento de `.join()` es el **segundo dataframe**\n",
    "- el argumento `on` define las columnas que identifican las mismas observaciones (tambien conocidas como **llaves** o *keys*)\n",
    "- el argumento opcional `how` toma tres valores:\n",
    "    - `\"left\"` indica que el resultado de la union debe preservar las observaciones del primer dataframe\n",
    "    - `\"right\"` indica que la union debe preservar las observaciones del segundo dataframe\n",
    "    - `\"inner\"` indica que la union de preservar las observaciones en ambos dataframes\n",
    "    \n",
    "`.merge()` es un metodo complejo que esta basado en manejo de bases de datos en SQL. La documentacion completa del comando esta [aqui](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norte['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regiones_norte['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regiones_norte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norte = df_norte.merge(df_regiones_norte, on='region', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos calcular la participacion dividiendo las columnas `recaudacion 2024` y `total region 2024`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norte['participacion 2024'] = df_norte['recaudacion 2024'] / df_norte['total region 2024']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.11 Guardando un dataframe como un archivo CSV\n",
    "\n",
    "Hemos producido 3 dataframes en estos ejercicios: `df_regiones`, `df_provincias` y `df_norte`. Guardaremos estos 3 resultados en archivos CSV para usarlos para visualizacion de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_regiones\n",
    "archivo = 'datos/regiones.csv'\n",
    "df_regiones.to_csv(archivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_provincias\n",
    "archivo = 'datos/provincias.csv'\n",
    "df_provincias.to_csv(archivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_norte\n",
    "archivo = 'datos/provincias_norte_2024.csv'\n",
    "df_norte.to_csv(archivo, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "foundations-s3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:python-dr-training]",
   "language": "python",
   "name": "conda-env-python-dr-training-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
